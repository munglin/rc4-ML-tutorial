{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "Training Set: 60000 images of 28 x 28 pixels each\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(\"Training Set: %s images of %s x %s pixels each\" %(Xtrain.shape[0],Xtrain.shape[1],Xtrain.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "Training Set: 10000 images of 28 x 28 pixels each\n"
     ]
    }
   ],
   "source": [
    "print(Xtest.shape)\n",
    "print(\"Training Set: %s images of %s x %s pixels each\" %(Xtest.shape[0],Xtest.shape[1],Xtest.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt to display some images in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(221 + i)\n",
    "    plt.imshow(Xtrain[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ground Truth: \" + str(Ytrain[i]) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(221 + i)\n",
    "    plt.imshow(Xtest[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ground Truth: \" + str(Ytest[i]) )\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_reshape = Xtrain.reshape(Xtrain.shape[0],-1)\n",
    "Xtest_reshape = Xtest.reshape(Xtest.shape[0],-1)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(Xtrain_reshape)\n",
    "Xtrain_reshape = scaler.transform(Xtrain_reshape)\n",
    "Xtest_reshape = scaler.transform(Xtest_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Building different models for the same problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Takeaway 1 <br> <br> Using different models for the same problem: Logistic Regression, Random Forest, MLP, CNNs</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Logistic Regression (Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ming\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Training Accuracy: 0.94025\n",
      "Test Accuracy: 0.9112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(verbose=2)\n",
    "LR.fit(Xtrain_reshape[:10000,:],Ytrain[:10000])\n",
    "#LR.fit(Xtrain_reshape,Ytrain)\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(LR.predict(Xtrain_reshape[:10000,:]),Ytrain[:10000])))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(LR.predict(Xtest_reshape),Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.987\n",
      "Test Accuracy: 0.8368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandForest = RandomForestClassifier(n_estimators=20,max_depth=8,min_samples_leaf=2)\n",
    "RandForest.fit(Xtrain_reshape[:1000,:],Ytrain[:1000])\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(RandForest.predict(Xtrain_reshape[:1000,:]),Ytrain[:1000])))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(RandForest.predict(Xtest_reshape),Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>Takeaway 2 <br> <br> Amount of Training Input Data <br> <br> More data gets you more accurate results.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9803\n",
      "Test Accuracy: 0.9396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators=200,max_depth=25,min_samples_leaf=7)\n",
    "RF.fit(Xtrain_reshape[:10000,:],Ytrain[:10000])\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(RF.predict(Xtrain_reshape[:10000,:]),Ytrain[:10000])))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(RF.predict(Xtest_reshape),Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 2.0204 - acc: 0.3975\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 1.4265 - acc: 0.6867\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 1.0082 - acc: 0.7927\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.7634 - acc: 0.8418\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.6283 - acc: 0.8674\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.5439 - acc: 0.8795\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.4865 - acc: 0.8888\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.4445 - acc: 0.8960\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.4125 - acc: 0.9006\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.3872 - acc: 0.9061\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.3667 - acc: 0.9108\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.3499 - acc: 0.9134\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.3350 - acc: 0.9165\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.3219 - acc: 0.9183\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.3108 - acc: 0.9213\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.3011 - acc: 0.9222\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2919 - acc: 0.9251\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2834 - acc: 0.9258\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.2761 - acc: 0.9270\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.2686 - acc: 0.9289\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.2620 - acc: 0.9299\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.2560 - acc: 0.9313\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2499 - acc: 0.9326\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2452 - acc: 0.9329\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2393 - acc: 0.9357\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2346 - acc: 0.9364\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2298 - acc: 0.9365\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2254 - acc: 0.9384: 0s - loss: 0.2231 - acc: 0.938\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.2210 - acc: 0.9386\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2167 - acc: 0.9404\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2128 - acc: 0.9412\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2094 - acc: 0.9411\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.2050 - acc: 0.9433\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.2018 - acc: 0.9446\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1981 - acc: 0.9449\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.1948 - acc: 0.9456\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.1913 - acc: 0.9475\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1880 - acc: 0.9479\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1848 - acc: 0.9480\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1822 - acc: 0.9494\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1785 - acc: 0.9501\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1760 - acc: 0.9502\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1732 - acc: 0.9524\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1703 - acc: 0.9523\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1680 - acc: 0.9532\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1650 - acc: 0.9543\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1624 - acc: 0.9544\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1597 - acc: 0.9553\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1574 - acc: 0.9573\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1551 - acc: 0.9572\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1527 - acc: 0.9584\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1506 - acc: 0.9590\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.1481 - acc: 0.9602\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 20us/step - loss: 0.1455 - acc: 0.9607\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 20us/step - loss: 0.1438 - acc: 0.9610\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1415 - acc: 0.9618\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1393 - acc: 0.9633\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.1372 - acc: 0.9631\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.1353 - acc: 0.9643: 0s - loss: 0.1434 - acc: \n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1334 - acc: 0.9644\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1315 - acc: 0.9655\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.1295 - acc: 0.9652\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1275 - acc: 0.9673\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1257 - acc: 0.9669\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1242 - acc: 0.9681\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 20us/step - loss: 0.1220 - acc: 0.9683\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1205 - acc: 0.9681\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1188 - acc: 0.9693\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1170 - acc: 0.9701\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.1155 - acc: 0.9705\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.1136 - acc: 0.9704\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1124 - acc: 0.9708\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.1110 - acc: 0.9721\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.1091 - acc: 0.9728\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.1075 - acc: 0.9723\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 0.1060 - acc: 0.9735\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.1046 - acc: 0.9740\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 0.1035 - acc: 0.9736\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.1017 - acc: 0.9753\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.1007 - acc: 0.9741\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0991 - acc: 0.9750\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0978 - acc: 0.9757\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0962 - acc: 0.9765\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0952 - acc: 0.9767\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.0937 - acc: 0.9772\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0926 - acc: 0.9777\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0914 - acc: 0.9777\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0900 - acc: 0.9782\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 0.0889 - acc: 0.9790\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 20us/step - loss: 0.0877 - acc: 0.9796\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0864 - acc: 0.9800\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0854 - acc: 0.9798\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0840 - acc: 0.9802\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0834 - acc: 0.9805\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0822 - acc: 0.9805\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0810 - acc: 0.9814\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0797 - acc: 0.9818: 0s - loss: 0.0794 - acc: 0.\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.0788 - acc: 0.9811\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 20us/step - loss: 0.0776 - acc: 0.9828\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0766 - acc: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18c8bdfec50>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "NN = keras.Sequential()\n",
    "NN.add(Dense(50, activation='relu'))\n",
    "NN.add(Dropout(0.7))\n",
    "NN.add(Dense(10, activation='softmax'))\n",
    "\n",
    "NN.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(0.0002),metrics=['accuracy'])\n",
    "NN.fit(Xtrain_reshape[:10000,:],Ytrain[:10000],batch_size=200,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN\n",
      "Training Accuracy: 0.9837\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"NN\")\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(NN.predict_classes(Xtrain_reshape[:10000,:]),Ytrain[:10000])))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(NN.predict_classes(Xtrain_reshape[:1000,:]),Ytrain[:1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>Takeaway 3 <br> <br> Do not mix training and test data!!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 20s 337us/step - loss: 0.4106 - acc: 0.8806\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1834 - acc: 0.9474\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1398 - acc: 0.9593\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1117 - acc: 0.9666\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0940 - acc: 0.9719\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0815 - acc: 0.9755\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0696 - acc: 0.9788\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0628 - acc: 0.9811\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0556 - acc: 0.9827: 0s - loss: 0.0517 - acc\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0483 - acc: 0.9852\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0467 - acc: 0.9858\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0406 - acc: 0.9871\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0368 - acc: 0.9886\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0339 - acc: 0.9893\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0332 - acc: 0.9896\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0279 - acc: 0.9912\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0241 - acc: 0.9927\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0242 - acc: 0.9921\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0219 - acc: 0.9934\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0202 - acc: 0.9936\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0168 - acc: 0.9950\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0190 - acc: 0.9938\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0163 - acc: 0.9945\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0151 - acc: 0.9951\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0174 - acc: 0.9940\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0130 - acc: 0.9960\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0147 - acc: 0.9950: 0s - loss: 0.0141 - acc\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0124 - acc: 0.9961\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0131 - acc: 0.9956\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0106 - acc: 0.9968\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0097 - acc: 0.9968\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0170 - acc: 0.9942\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0100 - acc: 0.9969\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0128 - acc: 0.9958\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0080 - acc: 0.9974\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0151 - acc: 0.9951\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0132 - acc: 0.9957\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0077 - acc: 0.9975\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0104 - acc: 0.9966\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0053 - acc: 0.9983\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0139 - acc: 0.9956\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0057 - acc: 0.9981: 0s - loss: 0.00\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 5.4649e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 4.6800e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 4.1164e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 3.9139e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 3.7830e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 3.6860e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 3.6007e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 3.4884e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 3.4254e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 3.3520e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 3.2993e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 3.2423e-04 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 3.1908e-04 - acc: 1.0000: 0s - loss: 6.6919e-\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 3.2192e-04 - acc: 1.000 - 2s 32us/step - loss: 3.1615e-04 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 3.1263e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 3.0612e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 3.2304e-04 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0844 - acc: 0.9818\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0117 - acc: 0.9964\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.998 - 1s 24us/step - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0037 - acc: 0.9988\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0045 - acc: 0.9987: 0s - loss: 0.0043 - acc: 0.998\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0083 - acc: 0.9971\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0071 - acc: 0.9976\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0054 - acc: 0.9985\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0039 - acc: 0.9989: 0s - loss: 0.0032 - a\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0091 - acc: 0.9973\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0124 - acc: 0.9963\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0041 - acc: 0.9986\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.0060 - acc: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18c8d7792b0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_deep = keras.Sequential()\n",
    "NN_deep.add(Dense(50, activation='relu'))\n",
    "NN_deep.add(Dense(30, activation='relu'))\n",
    "NN_deep.add(Dense(10, activation='softmax'))\n",
    "\n",
    "NN_deep.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(0.002),metrics=['accuracy'])\n",
    "NN_deep.fit(Xtrain_reshape,Ytrain,batch_size=200,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NN\")\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(NN_deep.predict_classes(Xtrain_reshape[:10000,:]),Ytrain[:10000])))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(NN_deep.predict_classes(Xtrain_reshape[:1000,:]),Ytrain[:1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>Takeaway 4 <br> <br> If you're not careful... your model can overfit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>A few things can be done to prevent overfitting: hyperparameter optimization, reducing the learning_rate, reducing the network size/parameters used, dropout </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red>For this instance, we attempt dropout to randomly set the nodes in the network to zero.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 1.1415 - acc: 0.6900\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.4007 - acc: 0.8941\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.3093 - acc: 0.9146\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2681 - acc: 0.9250\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2419 - acc: 0.9323\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2224 - acc: 0.9373\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2065 - acc: 0.9419\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1931 - acc: 0.9454\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1822 - acc: 0.9487\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1724 - acc: 0.9510\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1636 - acc: 0.9534: 1s - \n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1562 - acc: 0.9553\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1492 - acc: 0.9579\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1431 - acc: 0.9597\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1373 - acc: 0.9613\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1316 - acc: 0.9629\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1267 - acc: 0.9642\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1221 - acc: 0.9655\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1178 - acc: 0.9668\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1135 - acc: 0.9682\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1101 - acc: 0.9688\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1061 - acc: 0.9701\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1028 - acc: 0.9710\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0996 - acc: 0.9719\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0961 - acc: 0.9729\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0936 - acc: 0.9737\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0908 - acc: 0.9743\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0882 - acc: 0.9749\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0854 - acc: 0.9759\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0833 - acc: 0.9764\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0807 - acc: 0.9771\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0787 - acc: 0.9778\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0767 - acc: 0.9784\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0745 - acc: 0.9790\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0728 - acc: 0.9797\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0705 - acc: 0.9799\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0686 - acc: 0.9809\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0668 - acc: 0.9815\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0651 - acc: 0.9816\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0635 - acc: 0.9826\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0621 - acc: 0.9829\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0606 - acc: 0.9830\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0588 - acc: 0.9835\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0574 - acc: 0.9838\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0559 - acc: 0.9844\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0546 - acc: 0.9849\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0533 - acc: 0.9855\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0520 - acc: 0.9858\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0508 - acc: 0.9862\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0495 - acc: 0.9864\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0484 - acc: 0.9868\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0475 - acc: 0.9873\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0461 - acc: 0.9877\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0452 - acc: 0.9879\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0439 - acc: 0.9884\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0428 - acc: 0.9889\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0421 - acc: 0.9889\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0409 - acc: 0.9893\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0397 - acc: 0.9900\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0393 - acc: 0.9901\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0380 - acc: 0.9901\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0374 - acc: 0.9902\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0364 - acc: 0.9908\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0356 - acc: 0.9911\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0349 - acc: 0.9909\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0340 - acc: 0.9917\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0329 - acc: 0.9921\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0324 - acc: 0.9921\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0315 - acc: 0.9922\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0302 - acc: 0.9928: 0s - loss: 0\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0296 - acc: 0.9931\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0288 - acc: 0.9934\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0280 - acc: 0.9934\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0274 - acc: 0.9939\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0268 - acc: 0.9938\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0261 - acc: 0.9945\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0254 - acc: 0.9945\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0252 - acc: 0.9945\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0245 - acc: 0.9947\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0239 - acc: 0.9946\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0231 - acc: 0.9952\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0225 - acc: 0.9954\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0222 - acc: 0.9954\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0215 - acc: 0.9957\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0208 - acc: 0.9960\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0206 - acc: 0.9955\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.0199 - acc: 0.9962\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.0195 - acc: 0.9965\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0192 - acc: 0.9964\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0185 - acc: 0.9966\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0181 - acc: 0.9966\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0177 - acc: 0.9969\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0170 - acc: 0.9971: 1s - lo\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0167 - acc: 0.9970\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0164 - acc: 0.9970\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0158 - acc: 0.9972\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0155 - acc: 0.9975\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0150 - acc: 0.9976: 0s - loss: 0.0143 - a - ETA: 0s - loss: 0.0150 - acc: 0.\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0146 - acc: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18c88baf940>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP = keras.Sequential()\n",
    "MLP.add(Dense(50, activation='relu'))\n",
    "MLP.add(Dropout(0.7))\n",
    "MLP.add(Dense(30, activation='relu'))\n",
    "MLP.add(Dropout(0.7))\n",
    "MLP.add(Dense(10, activation='softmax'))\n",
    "\n",
    "MLP.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(0.0002),metrics=['accuracy'])\n",
    "MLP.fit(Xtrain_reshape,Ytrain,batch_size=200,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "Training Accuracy: 0.9974\n",
      "Test Accuracy: 0.9679\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP\")\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(MLP.predict_classes(Xtrain_reshape[:10000,:]),Ytrain[:10000])))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(MLP.predict_classes(Xtest_reshape),Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             multiple                  39250     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             multiple                  1530      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             multiple                  310       \n",
      "=================================================================\n",
      "Total params: 41,090\n",
      "Trainable params: 41,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLP.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Convolutional Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 47s 786us/step - loss: 0.9403 - acc: 0.7211\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 25s 422us/step - loss: 0.2838 - acc: 0.9155\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.2044 - acc: 0.9389\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 25s 411us/step - loss: 0.1610 - acc: 0.9510\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.1349 - acc: 0.9590\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.1166 - acc: 0.9644\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 28s 468us/step - loss: 0.1041 - acc: 0.9681\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0949 - acc: 0.9712\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 25s 413us/step - loss: 0.0877 - acc: 0.9734\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.0827 - acc: 0.9750\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 25s 423us/step - loss: 0.0773 - acc: 0.9769\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.0731 - acc: 0.9780\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0702 - acc: 0.9787\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.0668 - acc: 0.9793\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.0635 - acc: 0.9806\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0612 - acc: 0.9816\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.0592 - acc: 0.9822\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.0573 - acc: 0.9826\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.0554 - acc: 0.9833\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.0541 - acc: 0.9838\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0524 - acc: 0.9846\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0514 - acc: 0.9843\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0494 - acc: 0.9849\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0483 - acc: 0.9857\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 22s 370us/step - loss: 0.0469 - acc: 0.9863\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 22s 373us/step - loss: 0.0456 - acc: 0.9863\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0453 - acc: 0.9862\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 22s 363us/step - loss: 0.0442 - acc: 0.9867\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0427 - acc: 0.9872\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 0.0426 - acc: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18c86c1b710>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "CNN = keras.Sequential()\n",
    "CNN.add(Conv2D(12, (3, 3), activation='relu', input_shape=(Xtrain.shape[1], Xtrain.shape[2], 1)))\n",
    "CNN.add(MaxPooling2D((2, 2)))\n",
    "CNN.add(Conv2D(16, (4, 4), activation='relu'))\n",
    "CNN.add(MaxPooling2D((2, 2)))\n",
    "CNN.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(10, activation='softmax'))\n",
    "CNN.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(0.0002),metrics=['accuracy'])\n",
    "CNN.fit(Xtrain_reshape.reshape((Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[1], 1)),Ytrain,batch_size=100,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "Training Accuracy: 0.9878333333333333\n",
      "Test Accuracy: 0.9857\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN\")\n",
    "print(\"Training Accuracy: \" + str(accuracy_score(CNN.predict_classes( Xtrain_reshape.reshape(Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[1], 1)  ),Ytrain)))\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(CNN.predict_classes( Xtest_reshape.reshape(Xtest.shape[0], Xtest.shape[1], Xtest.shape[1], 1)  ),Ytest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 16)        3088      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                1450      \n",
      "=================================================================\n",
      "Total params: 6,978\n",
      "Trainable params: 6,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.save('CNN.h5')\n",
    "#CNN_load = tf.keras.models.load_model('CNN.h5')\n",
    "#print(\"Training Accuracy: \" + str(accuracy_score(CNN_load.predict_classes( Xtrain_reshape.reshape(Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[1], 1)  ),Ytrain)))\n",
    "#print(\"Test Accuracy: \" + str(accuracy_score(CNN_load.predict_classes( Xtest_reshape.reshape(Xtest.shape[0], Xtest.shape[1], Xtest.shape[1], 1)  ),Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red> 5. Visualising some of the incorrect predictions </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indices = np.where(np.not_equal(MLP.predict_classes(Xtest_reshape), Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, 2, 9, 6, 4, 9, 2, 5, 6, 3, 8, 1, 3, 5, 7, 4, 5, 7, 0, 8,\n",
       "       5, 1, 6, 6, 5, 7, 6, 2, 4, 3, 7, 6, 6, 9, 7, 9, 4, 9, 8, 8, 7, 5,\n",
       "       9, 8, 7, 7, 7, 8, 3, 4, 9, 6, 2, 0, 5, 3, 9, 8, 0, 4, 7, 2, 6, 8,\n",
       "       9, 7, 5, 9, 5, 6, 2, 0, 5, 8, 7, 1, 0, 7, 7, 5, 5, 4, 4, 3, 6, 4,\n",
       "       6, 9, 2, 5, 8, 9, 0, 5, 9, 8, 9, 9, 6, 8, 6, 2, 4, 5, 9, 9, 7, 3,\n",
       "       9, 6, 8, 9, 7, 4, 5, 8, 7, 3, 3, 4, 9, 9, 8, 1, 4, 5, 6, 7, 0, 2,\n",
       "       9, 4, 6, 2, 9, 6, 4, 5, 8, 8, 7, 9, 2, 8, 5, 8, 7, 6, 4, 2, 2, 0,\n",
       "       7, 6, 9, 5, 5, 1, 4, 3, 7, 0, 8, 9, 7, 8, 2, 2, 7, 1, 9, 2, 5, 4,\n",
       "       2, 9, 9, 9, 8, 9, 3, 3, 8, 7, 2, 9, 6, 2, 6, 5, 4, 8, 2, 3, 8, 3,\n",
       "       4, 8, 9, 4, 0, 8, 2, 8, 7, 3, 8, 3, 2, 3, 6, 1, 1, 1, 8, 7, 4, 3,\n",
       "       8, 4, 7, 7, 4, 4, 4, 5, 3, 5, 3, 5, 3, 3, 7, 3, 8, 3, 9, 0, 9, 3,\n",
       "       8, 0, 6, 9, 9, 9, 1, 5, 2, 7, 7, 0, 3, 8, 9, 0, 8, 8, 9, 6, 2, 0,\n",
       "       3, 8, 4, 6, 5, 2, 2, 8, 8, 3, 5, 3, 3, 1, 8, 1, 5, 2, 2, 6, 2, 3,\n",
       "       3, 6, 0, 2, 8, 5, 8, 4, 8, 4, 2, 7, 7, 7, 8, 9, 0, 2, 6, 6, 5, 4,\n",
       "       8, 2, 5, 6, 4, 6, 3, 2, 2, 7, 3, 3, 5], dtype=uint8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest[wrong_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 9, 9, 9, 8, 5, 2, 8, 7, 3, 0, 7, 2, 2, 9, 3, 3, 9, 8, 9, 2, 9,\n",
       "       4, 2, 0, 5, 8, 8, 8, 3, 6, 2, 8, 1, 5, 4, 2, 4, 9, 5, 3, 3, 9, 3,\n",
       "       7, 3, 9, 1, 9, 7, 5, 2, 8, 4, 3, 6, 9, 7, 3, 0, 7, 2, 2, 8, 4, 3,\n",
       "       8, 5, 7, 3, 8, 3, 0, 9, 8, 9, 2, 7, 5, 9, 9, 3, 4, 8, 9, 1, 0, 9,\n",
       "       1, 4, 3, 8, 0, 6, 2, 8, 1, 3, 8, 7, 4, 3, 8, 4, 9, 3, 4, 7, 1, 5,\n",
       "       5, 1, 5, 4, 1, 7, 3, 0, 3, 2, 2, 0, 7, 1, 5, 2, 6, 1, 5, 9, 9, 3,\n",
       "       1, 9, 0, 1, 1, 4, 9, 0, 5, 5, 8, 3, 8, 3, 3, 4, 2, 5, 6, 8, 3, 6,\n",
       "       1, 2, 4, 6, 3, 2, 2, 5, 1, 8, 5, 7, 9, 2, 3, 7, 9, 7, 7, 8, 6, 6,\n",
       "       8, 7, 7, 4, 4, 4, 2, 2, 7, 3, 7, 8, 5, 8, 2, 6, 9, 4, 4, 5, 7, 5,\n",
       "       6, 3, 6, 9, 8, 6, 8, 4, 1, 2, 5, 5, 7, 5, 4, 6, 8, 5, 4, 8, 3, 7,\n",
       "       2, 7, 4, 9, 0, 9, 9, 3, 9, 3, 8, 9, 9, 9, 3, 9, 3, 9, 3, 6, 0, 5,\n",
       "       9, 2, 2, 3, 4, 7, 3, 3, 6, 2, 2, 9, 5, 1, 5, 8, 5, 7, 4, 4, 7, 5,\n",
       "       7, 3, 8, 4, 8, 7, 7, 9, 9, 8, 8, 2, 2, 8, 1, 8, 8, 8, 8, 4, 4, 9,\n",
       "       5, 4, 6, 4, 5, 8, 0, 8, 6, 9, 8, 2, 2, 2, 5, 4, 3, 7, 3, 5, 6, 3,\n",
       "       5, 0, 0, 5, 9, 5, 5, 3, 3, 9, 5, 8, 6], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.predict_classes(Xtest_reshape)[wrong_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(221 + i)\n",
    "    plt.imshow(Xtest[wrong_indices[0][i]], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Truth: \" + str(Ytest[wrong_indices[0][i]]) + \", Predicted: \" +str(MLP.predict_classes(Xtest_reshape)[wrong_indices[0][i]])  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(221 + i)\n",
    "    plt.imshow(Xtest[wrong_indices[0][4+i]], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Truth: \" + str(Ytest[wrong_indices[0][i+4]]) + \", Predicted: \" +str(MLP.predict_classes(Xtest_reshape)[wrong_indices[0][4+i]])  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red> Neural network parameters: Optimisers, number of epoches, network parameters, optimisers, batch size, different types of layers, convolutional layers VS dense layers </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=red> Machine Learning concepts: Backpropagation, global vs local minima, explainability, hyperparameter optimization, activation functions, probability outputs </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For further reference: Stanford CS231n Convolutional Neural Networks, 2 Blue 1 Brown Neural Networks, Tensorflow Documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
